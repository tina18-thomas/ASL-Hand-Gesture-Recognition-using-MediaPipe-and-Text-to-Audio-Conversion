# ASL-Hand-Gesture-Recognition-using-MediaPipe-and-Text-to-Audio-Conversion
Real-time American Sign Language (ASL) hand gesture recognition system using OpenCV, MediaPipe, and a Random Forest classifier. Collect, train, and deploy your own ASL dataset with ease.

# ASL Hand Gesture Recognition using MediaPipe & Random Forest

A real-time hand gesture recognition system that detects and classifies American Sign Language (ASL) signs using MediaPipe for hand landmark extraction and a Random Forest classifier for prediction. Designed for quick dataset collection, simple training, and fast real-time inference via webcam.

---

## ğŸ” Project Description

This project aims to help bridge the communication gap for the hearing- and speech-impaired by enabling real-time classification of static ASL signs. It uses computer vision and machine learning to:
- Collect gesture image data using a webcam.
- Extract hand landmarks using MediaPipe.
- Train a Random Forest classifier on the normalized coordinates of hand keypoints.
- Perform real-time inference and overlay the predicted gesture on the video feed.

---

## ğŸ¯ Features

- âœ… Custom dataset collection for multiple ASL classes
- âœ… MediaPipe-based landmark extraction
- âœ… Data normalization and storage with `pickle`
- âœ… Model training using Random Forest Classifier
- âœ… Real-time ASL inference using webcam
- âœ… Easily extensible for more ASL signs

---

## ğŸ§  Tech Stack

- **Python**
- **OpenCV**
- **MediaPipe**
- **Scikit-learn**
- **NumPy / Pickle / Matplotlib**

---


